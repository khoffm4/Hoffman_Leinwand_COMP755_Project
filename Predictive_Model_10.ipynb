{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "Total_dataframe = pandas.read_csv('neighbors_2017_combined_train_and_test_with_predictions_fixed_with_zeros.csv', usecols=[4,3,10,11,13])\n",
    "PUL_list = numpy.unique(Total_dataframe['PU_DO'])\n",
    "RMSE_list = [0] * len(PUL_list)\n",
    "MAPE_list = [0] * len(PUL_list)\n",
    "\n",
    "#delete warning flag\n",
    "pandas.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "for i in range(1):    \n",
    "    print(i/len(PUL_list))\n",
    "    PULoc = PUL_list[i]\n",
    "    \n",
    "    #Training/testing Split\n",
    "    dataframe = Total_dataframe\n",
    "    dataframe = dataframe[dataframe['PU_DO'] == PULoc]\n",
    "    dataframe = dataframe['time_delta']\n",
    "    dataset = dataframe.values\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = numpy.reshape(dataset, (len(dataset),1))\n",
    "\n",
    "\n",
    "    #Scalar transform\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "\n",
    "    dataframe = Total_dataframe\n",
    "    dataframe = dataframe[dataframe['PU_DO'] == PULoc]\n",
    "    dataframe['time_delta'] = dataset\n",
    "    dataframe = dataframe[dataframe['month'] <= 10]\n",
    "    dataframe2 = dataframe[dataframe['month'] >= 10]\n",
    "    dataframe['time_delta']\n",
    "    dataframe2 = dataframe2['time_delta']\n",
    "    dataset2 = dataframe2.values\n",
    "    dataset2 = dataset2.astype('float32')\n",
    "    dataset2 = numpy.reshape(dataset2, (len(dataset2),1))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    #Training/Testing Data (Train on Jan-Oct, Ttest on Nov-Dec) 370472 is index\n",
    "    train_size = int(len(dataset) * 0.9)\n",
    "    test_size = len(dataset) - train_size\n",
    "    test2_size = len(dataset2)\n",
    "    train = dataset[0:train_size,:]\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "    test2 = dataset2\n",
    "\n",
    "    def create_dataset(dataset, look_back=1):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-look_back-1):\n",
    "            a = dataset[i:(i+look_back), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back, 0])\n",
    "        return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "    # reshape into X=t and Y=t+1\n",
    "    look_back = 1\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    test2X, test2Y = create_dataset(test2, look_back)\n",
    "\n",
    "    # reshape input to be [samples, time steps, features]\n",
    "    trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "    testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "    test2X = numpy.reshape(test2X, (test2X.shape[0], 1, test2X.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "    # create and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    #model.add(LSTM(1, input_shape=(1, look_back)))\n",
    "    model.add(LSTM(4))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=5, batch_size=10, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # make predictions\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    test2Predict = model.predict(test2X)\n",
    "     #invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform([trainY])\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform([testY])\n",
    "    test2Predict = scaler.inverse_transform(test2Predict)\n",
    "    test2Y = scaler.inverse_transform([test2Y])\n",
    "    # calculate root mean squared error\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "    test2Score = math.sqrt(mean_squared_error(test2Y[0], test2Predict[:,0]))\n",
    "    print('Test2 Score: %.2f RMSE' % (test2Score))\n",
    "\n",
    "           #\n",
    "    #print('training actual:', trainY[0])\n",
    "    #print('training predict:', trainPredict[:,0]  )\n",
    "    #print(numpy.mean(abs(trainY[0]   -trainPredict[:,0]  )))\n",
    "\n",
    "    #print('testing actual:', testY[0] )\n",
    "    #print('testing predict:', testPredict[:,0] )\n",
    "    #print(numpy.mean( abs(testY[0] - testPredict[:,0]  )))\n",
    "\n",
    "    # shift train predictions for plotting\n",
    "    #trainPredictPlot = numpy.empty_like(dataset)\n",
    "    #trainPredictPlot[:, :] = numpy.nan\n",
    "    #trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "    # shift test predictions for plotting\n",
    "    #testPredictPlot = numpy.empty_like(dataset)\n",
    "    #testPredictPlot[:, :] = numpy.nan\n",
    "    #testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "    # plot baseline and predictions\n",
    "    #plt.plot(scaler.inverse_transform(dataset))\n",
    "    #plt.plot(trainPredictPlot)\n",
    "    #plt.plot(testPredictPlot)\n",
    "\n",
    "\n",
    "    RMSE_list[i] = test2Score\n",
    "    Test2_MAPE = numpy.mean(abs(test2Y[0]- test2Predict[:,0] ))  \n",
    "    MAPE_list[i] = Test2_MAPE\n",
    "    print('Test_MAD:', Test2_MAPE)\n",
    "    \n",
    "    #print('Testy:', (testY[0])[0:10])\n",
    "    #print('Testpredict:', testPredict[:,0])\n",
    "    \n",
    "    Test_MAPE = numpy.mean(abs(testY[0]- testPredict[:,0] )  )  \n",
    "    print('Validation_MAD:', Test_MAPE)\n",
    "\n",
    "    Test2_MAD = numpy.mean(abs(test2Y[0]- test2Predict[:,0]))\n",
    "    Test_MAD = numpy.mean(abs(testY[0]- testPredict[:,0]))\n",
    "    #print('Test_MAD:', Test2_MAPE)\n",
    "    #print('Validation_MAD:', Test_MAPE)\n",
    "    \n",
    "    #Save the Model\n",
    "    filename = 'Time_LSTM' + str(i)  +'.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.savetxt(\"LSTM_Time_MAD.csv\", MAD_list, delimiter=\",\")\n",
    "numpy.savetxt(\"LSTM_Time_RMSE.csv\", RMSE_list, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time_LSTM99.sav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "illegal target for annotation (<ipython-input-3-b471e228d8a5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-b471e228d8a5>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    219:range(len([0]))\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m illegal target for annotation\n"
     ]
    }
   ],
   "source": [
    "219:range(len([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
